from wordcloud import WordCloud
import matplotlib.pyplot as plt
import numpy as np
import os
from sklearn.decomposition import PCA
from sklearn.preprocessing import MinMaxScaler

def wordcloud(word_dict):
    wc = WordCloud(
        background_color="white",
        font_path="C:/Windows/Fonts/simkai.ttf",
        max_words=600,
    )
    wc.generate_from_frequencies(word_dict)
    # print(word_dict)
    plt.axis("off")
    # plt.imshow(wc, interpolation='bilinear')
    wc.to_file(os.path.join(os.getcwd(), "wordcloud.png"))
    return None

'''
ç›®æ ‡ï¼šç»™å‡ºç›¸åº”ä»»åŠ¡ç»“æœï¼Œè®­ç»ƒé›†å’Œæµ‹è¯•é›†ç²¾åº¦ï¼Œä»¥åŠç‰¹å¾é™ç»´åçš„å¯è§†åŒ–
ä½¿ç”¨5ç§ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•è¿›è¡ŒäºŒåˆ†ç±»ï¼šå†³ç­–æ ‘ã€SVMã€KNNã€æœ´ç´ è´å¶æ–¯ã€é€»è¾‘å›å½’
'''
# æ€»å…±ç”»5ä¸ªå›¾å°±è¡Œï¼Œåˆ†3ä¸ªç”»å›¾å‡½æ•°ï¼ˆç²¾åº¦ã€å¬å›ç‡ã€å‡†ç¡®åº¦ï¼‰ï¼Œå­˜å‚¨ä¸ºä¸‰å¼ å›¾ç‰‡ï¼Œå‰ä¸¤å¼ å›¾ç‰‡å«æœ‰2ä¸ªå­å›¾ï¼Œéƒ½æ˜¯è®­ç»ƒé›†å’Œæµ‹è¯•é›†å¯¹æ¯”
def plotting_precision(name_list, pos_train, pos_test, neg_train, neg_test):
    x = np.arange(5)
    width = 0.25  # æŸ±å­çš„å®½åº¦
    plt.figure(figsize=(12,9))
    # è®¡ç®—æ¯ä¸ªæŸ±å­åœ¨xè½´ä¸Šçš„ä½ç½®ï¼Œä¿è¯xè½´åˆ»åº¦æ ‡ç­¾å±…ä¸­
    # x - width/2ï¼Œx + width/2å³æ¯ç»„æ•°æ®åœ¨xè½´ä¸Šçš„ä½ç½®

    # æ­£ç±»ç²¾åº¦
    plt.subplot(121)
    plt.bar(x - width / 2, pos_train, width=0.25, label='train', color="cornflowerblue")
    plt.bar(x + width / 2, pos_test, width=0.25, label='test', color="lightpink")
    plt.xlabel("Method")
    plt.ylabel('Scores')
    plt.xticks(range(x.shape[0]), name_list)
    plt.title("positive-label precision comparison")
    plt.legend()

    # è´Ÿç±»ç²¾åº¦
    plt.subplot(122)
    plt.bar(x - width / 2, neg_train, width=0.25, label='train', color="cornflowerblue")
    plt.bar(x + width / 2, neg_test, width=0.25, label='test', color="lightpink")
    plt.xlabel("Method")
    plt.ylabel('Scores')
    plt.xticks(range(x.shape[0]), name_list)
    plt.title("negative-label precision comparison")
    plt.legend()

    # ä¿å­˜å¹¶æ˜¾ç¤ºå›¾ç‰‡
    plt.savefig("./ML_Res/precision comparison.png")
    # plt.show()


def plotting_recall(name_list, pos_train, pos_test, neg_train, neg_test):
    x = np.arange(5)
    width = 0.25  # æŸ±å­çš„å®½åº¦
    plt.figure(figsize=(12,9))
    # è®¡ç®—æ¯ä¸ªæŸ±å­åœ¨xè½´ä¸Šçš„ä½ç½®ï¼Œä¿è¯xè½´åˆ»åº¦æ ‡ç­¾å±…ä¸­
    # x - width/2ï¼Œx + width/2å³æ¯ç»„æ•°æ®åœ¨xè½´ä¸Šçš„ä½ç½®

    # æ­£ç±»å¬å›ç‡
    plt.subplot(121)
    plt.bar(x - width / 2, pos_train, width=0.25, label='train', color="royalblue")
    plt.bar(x + width / 2, pos_test, width=0.25, label='test', color="orangered")
    plt.xlabel("Method")
    plt.ylabel('Scores')
    plt.xticks(range(x.shape[0]), name_list)
    plt.title("positive-label recall comparison")
    plt.legend()

    # è´Ÿç±»å¬å›ç‡
    plt.subplot(122)
    plt.bar(x - width / 2, neg_train, width=0.25, label='train', color="royalblue")
    plt.bar(x + width / 2, neg_test, width=0.25, label='test', color="orangered")
    plt.xlabel("Method")
    plt.ylabel('Scores')
    plt.xticks(range(x.shape[0]), name_list)
    plt.title("negative-label recall comparison")
    plt.legend()

    # ä¿å­˜å¹¶æ˜¾ç¤ºå›¾ç‰‡
    plt.savefig("./ML_Res/recall comparison.png")
    # plt.show()
    plt.clf()

# å‡†ç¡®åº¦ç”¨æŠ˜çº¿å›¾ç”»å§ï¼Œæ”¾åœ¨åŒä¸€å¼ å›¾ç‰‡é‡Œ
def plotting_acc(name_list, train_acc, test_acc):
    x = np.arange(5)
    plt.axis("on")
    plt.xlabel("Method")
    plt.ylabel('Scores')
    plt.xlim(0, 1)
    plt.ylim(0, 1)
    plt.xticks(range(x.shape[0]), name_list)
    plt.title("accuracy comparison")

    # è®­ç»ƒé›†å‡†ç¡®åº¦
    plt.plot(x, train_acc, color="r", label="training_set")
    # æµ‹è¯•é›†å‡†ç¡®åº¦
    plt.plot(x, test_acc, color="b",  label="test_set")

    # ä¿å­˜å¹¶æ˜¾ç¤ºå›¾ç‰‡
    plt.legend()
    plt.savefig("./ML_Res/accuracy comparison.png")
    plt.clf()

def plotting_loss_acc(train_loss, test_acc, epoch):
    plt.figure(figsize=(12, 9))
    plt.subplot(121)
    plt.plot(np.arange(epoch), train_loss, color='r', label="train_loss")
    plt.xlabel("epoch")
    plt.ylabel("train_loss")
    plt.title("epoch--train_loss")
    plt.legend()

    plt.subplot(122)
    plt.plot(np.arange(epoch), test_acc, color='b', label="test_acc")
    plt.xlabel("epoch")
    plt.ylabel("test_acc")
    plt.title("epoch--test_acc")
    plt.legend()

    plt.savefig("./DL_Res/loss and acc.png")
    plt.clf()



# é™ç»´å¯è§†åŒ–ï¼Œå‘ƒå‘ƒå‘ƒæ„Ÿè§‰æ²¡å•¥ç”¨ï¼Œå”‰ğŸ˜”
def visualize(X, y):
    # é¢œè‰²è®¾ç½®
    color = ['r', 'b']

    # PCAé™ç»´ï¼ˆä¸€ç§çŸ©é˜µåˆ†è§£çš„æ–¹æ³•ï¼‰
    pca = PCA(n_components=3, random_state=42)
    result = pca.fit_transform(X)
    # å½’ä¸€åŒ–å¤„ç†
    scaler = MinMaxScaler(feature_range=(-2., 2.), copy=True)
    result = scaler.fit_transform(result)
    # å¯è§†åŒ–å±•ç¤º
    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot(111, projection='3d')
    # æ ‡é¢˜ï¼ŒèŒƒå›´ï¼Œæ ‡ç­¾è®¾ç½®
    ax.set_title('PCA process')
    ax.set_xlim((-2.1, 2.1))
    ax.set_ylim((-2.1, 2.1))
    ax.set_zlim((-2.1, 2.1))
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_zlabel('Z')
    # ç»˜åˆ¶æ•£ç‚¹å›¾ï¼ˆç›´æ¥åœ¨å¯¹åº”ä½ç½®ä¸Šç”»å‡ºæ ‡ç­¾å€¼ï¼‰
    for i in range(len(result)):
        ax.text(result[i, 0], result[i, 1], result[i, 2], str(y[i]),
                color=color[y[i]], fontdict={'weight': 'bold', 'size': 9})

    # plt.show()
    plt.savefig("./DL_Res/PCA_Visualization.png")
    plt.clf()